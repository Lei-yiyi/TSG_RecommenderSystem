"""
DeepFMï¼š
DeepFMæ¨¡å‹å¤§è‡´ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¸€éƒ¨åˆ†æ˜¯FMï¼Œè¿˜æœ‰ä¸€éƒ¨åˆ†å°±æ˜¯DNNï¼Œè€ŒFMåˆç”±ä¸€é˜¶ç‰¹å¾éƒ¨åˆ†ä¸äºŒé˜¶ç‰¹å¾äº¤å‰éƒ¨åˆ†ç»„æˆï¼Œæ‰€ä»¥å¯ä»¥å°†æ•´ä¸ªæ¨¡å‹æ‹†æˆä¸‰éƒ¨åˆ†ï¼Œ
åˆ†åˆ«æ˜¯FMçš„ä¸€é˜¶ç‰¹å¾ï¼ŒFMçš„äºŒé˜¶ç‰¹å¾äº¤å‰ä»¥åŠDNNçš„é«˜é˜¶ç‰¹å¾äº¤å‰ã€‚æ­¤å¤–æ¯ä¸€éƒ¨åˆ†å¯èƒ½æ˜¯ç”±ä¸åŒçš„ç‰¹å¾ç»„æˆï¼Œæ‰€ä»¥åœ¨æ„å»ºæ¨¡å‹çš„æ—¶å€™éœ€è¦åˆ†åˆ«å¯¹è¿™ä¸‰éƒ¨åˆ†
è¾“å…¥çš„ç‰¹å¾è¿›è¡Œé€‰æ‹©ã€‚

linear_logits: è¿™ä¸€å—ä¸»è¦æ˜¯é’ˆå¯¹è¿ç»­ç‰¹å¾å’Œç¦»æ•£ç‰¹å¾ï¼Œå°†è¿ç»­ç‰¹å¾å’Œç¦»æ•£ç‰¹å¾çš„onehotç¼–ç ç»„æˆä¸€ç»´å‘é‡ï¼ˆå®é™…åº”ç”¨ä¸­æ ¹æ®è‡ªå·±çš„ä¸šåŠ¡æ”¾ç½®ä¸åŒ
çš„ä¸€é˜¶ç‰¹å¾ï¼‰ï¼Œæœ€åè®¡ç®—FMçš„ä¸€é˜¶ç‰¹å¾ï¼ˆå³FMçš„å‰åŠéƒ¨åˆ† ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2...ğ‘¤ğ‘›ğ‘¥ğ‘› + ğ‘ çš„çº¿æ€§è®¡ç®—ï¼‰çš„logitså€¼

fm_logits: è¿™ä¸€å—ä¸»è¦æ˜¯é’ˆå¯¹ç¦»æ•£ç‰¹å¾ï¼Œé¦–å…ˆè¿‡embeddingï¼Œç„¶åä½¿ç”¨FMç‰¹å¾äº¤å‰çš„æ–¹å¼ï¼ˆåªè€ƒè™‘ä¸¤ä¸¤ç‰¹å¾è¿›è¡Œäº¤å‰ï¼‰å¾—åˆ°æ–°çš„ç‰¹å¾å‘é‡ï¼Œæœ€åè®¡ç®—
FMçš„äºŒé˜¶äº¤å‰ç‰¹å¾çš„logitså€¼

dnn_logits: è¿™ä¸€å—ä¸»è¦æ˜¯é’ˆå¯¹ç¦»æ•£ç‰¹å¾ï¼Œé¦–å…ˆè¿‡embeddingï¼Œç„¶åå°†å¾—åˆ°çš„embeddingæ‹¼æ¥æˆä¸€ä¸ªå‘é‡ï¼Œé€šè¿‡dnnå­¦ä¹ ç‰¹å¾ä¹‹é—´çš„éšå¼ç‰¹å¾äº¤å‰ï¼Œ
æœ€åè®¡ç®—DNNçš„é«˜é˜¶äº¤å‰ç‰¹å¾çš„logitså€¼


ä»»åŠ¡ï¼š
å¼€å‘é¢„æµ‹å¹¿å‘Šç‚¹å‡»ç‡(CTR)çš„æ¨¡å‹ã€‚å³ç»™å®šä¸€ä¸ªç”¨æˆ·å’Œä»–æ­£åœ¨è®¿é—®çš„é¡µé¢ï¼Œé¢„æµ‹ä»–ç‚¹å‡»ç»™å®šå¹¿å‘Šçš„æ¦‚ç‡ã€‚


æ•°æ®é›†ï¼š
Labelï¼šç›®æ ‡å˜é‡ï¼Œ0è¡¨ç¤ºæœªç‚¹å‡»ï¼Œ 1è¡¨ç¤ºç‚¹å‡»
l1 - l13: 13åˆ—çš„æ•°å€¼ç‰¹å¾
C1 - C26: 26åˆ—çš„ç±»åˆ«ç‰¹å¾
"""


import itertools
import pandas as pd
import numpy as np
from tqdm import tqdm
from collections import namedtuple

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import *

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

import warnings
warnings.filterwarnings("ignore")


"""æ•°æ®é¢„å¤„ç†"""


def data_process(data_df, dense_features, sparse_features):
    # sparseç‰¹å¾å¡«å……ç¼ºå¤±å€¼
    data_df[dense_features] = data_df[dense_features].fillna(0.0)
    # æ•°å€¼å¤„ç†
    for f in dense_features:
        data_df[f] = data_df[f].apply(lambda x: np.log(x + 1) if x > -1 else -1)

    # denseç‰¹å¾å¡«å……ç¼ºå¤±å€¼
    data_df[sparse_features] = data_df[sparse_features].fillna("-1")
    # ç±»åˆ«ç¼–ç 
    for f in sparse_features:
        lbe = LabelEncoder()
        data_df[f] = lbe.fit_transform(data_df[f])

    return data_df[dense_features + sparse_features]


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”è¾“å…¥å±‚"""


# æ„å»ºè¾“å…¥å±‚ï¼Œè¿™é‡Œä½¿ç”¨å­—å…¸ï¼ˆdenseå’Œsparseä¸¤ç±»å­—å…¸ï¼‰çš„å½¢å¼è¿”å›ï¼Œæ–¹ä¾¿åç»­æ„å»ºæ¨¡å‹
def build_input_layers(feature_columns):
    dense_input_dict, sparse_input_dict = {}, {}

    for fc in feature_columns:
        if isinstance(fc, SparseFeat):
            sparse_input_dict[fc.name] = Input(shape=(1,), name=fc.name)
        elif isinstance(fc, DenseFeat):
            dense_input_dict[fc.name] = Input(shape=(fc.dimension,), name=fc.name)

    return dense_input_dict, sparse_input_dict


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”ç»´åº¦ä¸ºkçš„embeddingå±‚"""


# æ„å»ºç»´åº¦ä¸ºkçš„embeddingå±‚ï¼Œè¿™é‡Œä½¿ç”¨å­—å…¸çš„å½¢å¼è¿”å›ï¼Œæ–¹ä¾¿åé¢æ­å»ºæ¨¡å‹
def build_embedding_layers(feature_columns, input_layers_dict, is_linear):
    # å®šä¹‰ä¸€ä¸ªembeddingå±‚å¯¹åº”çš„å­—å…¸
    embedding_layers_dict = dict()

    # å°†ç‰¹å¾ä¸­çš„sparseç‰¹å¾ç­›é€‰å‡ºæ¥
    sparse_feature_columns = list(
        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []

    # å¦‚æœæ˜¯ç”¨äºçº¿æ€§éƒ¨åˆ†çš„embeddingå±‚ï¼Œå…¶ç»´åº¦ä¸º1ï¼Œå¦åˆ™ç»´åº¦å°±æ˜¯è‡ªå·±å®šä¹‰çš„embeddingç»´åº¦
    if is_linear:
        for fc in sparse_feature_columns:
            embedding_layers_dict[fc.name] = Embedding(fc.vocabulary_size, 1, name='1d_emb_' + fc.name)
    else:
        for fc in sparse_feature_columns:
            embedding_layers_dict[fc.name] = Embedding(fc.vocabulary_size, fc.embedding_dim, name='kd_emb_' + fc.name)

    return embedding_layers_dict


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”è¾“å‡ºå±‚ linear_logits"""


# linear_logitsè®¡ç®—denseç‰¹å¾çš„logitså’Œsparseç‰¹å¾çš„logitsä¸¤éƒ¨åˆ†ï¼Œæœ€åè®¡ç®—FMçš„ä¸€é˜¶ç‰¹å¾çš„logitså€¼
def get_linear_logits(dense_input_dict, sparse_input_dict, sparse_feature_columns):
    """
        è°ƒç”¨å‡½æ•°ï¼šbuild_embedding_layers
    """
    # å°†æ‰€æœ‰çš„denseç‰¹å¾çš„Inputå±‚ï¼Œç„¶åç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚å¾—åˆ°denseç‰¹å¾çš„logits
    concat_dense_inputs = Concatenate(axis=1)(list(dense_input_dict.values()))
    dense_logits_output = Dense(1)(concat_dense_inputs)

    # è·å–linearéƒ¨åˆ†sparseç‰¹å¾çš„embeddingå±‚ï¼Œè¿™é‡Œ
    # ä½¿ç”¨embeddingå±‚çš„åŸå› æ˜¯ï¼šå¯¹äºlinearéƒ¨åˆ†ç›´æ¥å°†ç‰¹å¾è¿›è¡Œonehotç„¶åé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå½“ç»´åº¦ç‰¹åˆ«å¤§çš„æ—¶å€™ï¼Œè®¡ç®—æ¯”è¾ƒæ…¢
    # ä½¿ç”¨embeddingå±‚çš„å¥½å¤„æ˜¯ï¼šå¯ä»¥é€šè¿‡æŸ¥è¡¨çš„æ–¹å¼è·å–åˆ°å“ªäº›éé›¶çš„å…ƒç´ å¯¹åº”çš„æƒé‡ï¼Œç„¶ååœ¨å°†è¿™äº›æƒé‡ç›¸åŠ ï¼Œæ•ˆç‡æ¯”è¾ƒé«˜
    linear_embedding_layers = build_embedding_layers(sparse_feature_columns, sparse_input_dict, is_linear=True)

    # å°†ä¸€ç»´çš„embeddingæ‹¼æ¥ï¼Œæ³¨æ„è¿™é‡Œéœ€è¦ä½¿ç”¨ä¸€ä¸ªFlattenå±‚ï¼Œä½¿ç»´åº¦å¯¹åº”
    sparse_1d_embed = []
    for fc in sparse_feature_columns:
        feat_input = sparse_input_dict[fc.name]
        embed = Flatten()(linear_embedding_layers[fc.name](feat_input))  # B x 1
        sparse_1d_embed.append(embed)

    # embeddingä¸­æŸ¥è¯¢å¾—åˆ°çš„æƒé‡å°±æ˜¯å¯¹åº”onehotå‘é‡ä¸­ä¸€ä¸ªä½ç½®çš„æƒé‡ï¼Œæ‰€ä»¥åé¢ä¸ç”¨å†æ¥ä¸€ä¸ªå…¨è¿æ¥äº†ï¼Œæœ¬èº«ä¸€ç»´çš„embeddingå°±ç›¸å½“äºå…¨è¿æ¥
    # åªä¸è¿‡æ˜¯è¿™é‡Œçš„è¾“å…¥ç‰¹å¾åªæœ‰0å’Œ1ï¼Œæ‰€ä»¥ç›´æ¥å‘éé›¶å…ƒç´ å¯¹åº”çš„æƒé‡ç›¸åŠ å°±ç­‰åŒäºè¿›è¡Œäº†å…¨è¿æ¥æ“ä½œ(éé›¶å…ƒç´ éƒ¨åˆ†ä¹˜çš„æ˜¯1)
    sparse_logits_output = Add()(sparse_1d_embed)

    # æœ€ç»ˆå°†denseç‰¹å¾å’Œsparseç‰¹å¾å¯¹åº”çš„logitsç›¸åŠ ï¼Œå¾—åˆ°æœ€ç»ˆlinearçš„logits
    linear_logits = Add()([dense_logits_output, sparse_logits_output])
    return linear_logits


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”è¾“å‡ºå±‚ fm_logits"""


class FM_Layer(Layer):
    def __init__(self):
        super(FM_Layer, self).__init__()

    def call(self, inputs):
        # ä¼˜åŒ–åçš„å…¬å¼ä¸ºï¼š 0.5 * æ±‚å’Œï¼ˆå’Œçš„å¹³æ–¹-å¹³æ–¹çš„å’Œï¼‰  =>> B x 1
        concated_embeds_value = inputs  # B x n x k

        square_of_sum = tf.square(tf.reduce_sum(concated_embeds_value, axis=1, keepdims=True))  # B x 1 x k
        sum_of_square = tf.reduce_sum(concated_embeds_value * concated_embeds_value, axis=1, keepdims=True)  # B x1 xk
        cross_term = square_of_sum - sum_of_square  # B x 1 x k
        cross_term = 0.5 * tf.reduce_sum(cross_term, axis=2, keepdims=False)  # B x 1

        return cross_term

    def compute_output_shape(self, input_shape):
        return (None, 1)


# fm_logitsåªè€ƒè™‘sparseç‰¹å¾çš„äºŒé˜¶äº¤å‰ï¼Œå°†æ‰€æœ‰çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œæœ€åè®¡ç®—FMçš„äºŒé˜¶äº¤å‰ç‰¹å¾çš„logitså€¼
def get_fm_logits(sparse_input_dict, sparse_feature_columns, dnn_embedding_layers):
    """
        è°ƒç”¨å‡½æ•°ï¼šFM_Layer
    """
    # å°†ç‰¹å¾ä¸­çš„sparseç‰¹å¾ç­›é€‰å‡ºæ¥
    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), sparse_feature_columns))

    # åªè€ƒè™‘sparseç‰¹å¾çš„äºŒé˜¶äº¤å‰ï¼Œå°†æ‰€æœ‰çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œæœ€åè®¡ç®—FMçš„äºŒé˜¶äº¤å‰ç‰¹å¾çš„logitså€¼
    # å› ä¸ºç±»åˆ«å‹æ•°æ®è¾“å…¥çš„åªæœ‰0å’Œ1ï¼Œæ‰€ä»¥ä¸éœ€è¦è€ƒè™‘å°†éšå‘é‡ä¸xç›¸ä¹˜ï¼Œç›´æ¥å¯¹éšå‘é‡è¿›è¡Œæ“ä½œå³å¯
    sparse_kd_embed = []
    for fc in sparse_feature_columns:
        feat_input = sparse_input_dict[fc.name]
        _embed = dnn_embedding_layers[fc.name](feat_input)  # B x 1 x k
        sparse_kd_embed.append(_embed)

    # å°†æ‰€æœ‰sparseçš„embeddingæ‹¼æ¥èµ·æ¥ï¼Œå¾—åˆ° (n, k)çš„çŸ©é˜µï¼Œå…¶ä¸­nä¸ºç‰¹å¾æ•°ï¼Œkä¸ºembeddingå¤§å°
    concat_sparse_kd_embed = Concatenate(axis=1)(sparse_kd_embed)  # B x n x k
    fm_cross_out = FM_Layer()(concat_sparse_kd_embed)

    return fm_cross_out


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”è¾“å‡ºå±‚ dnn_logits"""


# dnn_logitsåªè€ƒè™‘sparseç‰¹å¾çš„é«˜é˜¶äº¤å‰ï¼Œå°†æ‰€æœ‰çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·è¾“å…¥åˆ°dnnä¸­ï¼Œæœ€åè®¡ç®—DNNçš„é«˜é˜¶äº¤å‰ç‰¹å¾çš„logitså€¼
def get_dnn_logits(sparse_input_dict, sparse_feature_columns, dnn_embedding_layers):
    # å°†ç‰¹å¾ä¸­çš„sparseç‰¹å¾ç­›é€‰å‡ºæ¥
    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), sparse_feature_columns))

    # å°†æ‰€æœ‰éé›¶çš„sparseç‰¹å¾å¯¹åº”çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·
    sparse_kd_embed = []
    for fc in sparse_feature_columns:
        feat_input = sparse_input_dict[fc.name]
        _embed = dnn_embedding_layers[fc.name](feat_input)  # B x 1 x k
        _embed = Flatten()(_embed)  # B x k
        sparse_kd_embed.append(_embed)

    concat_sparse_kd_embed = Concatenate(axis=1)(sparse_kd_embed)  # B x nk

    # dnnå±‚ï¼Œè¿™é‡Œçš„Dropoutå‚æ•°ï¼ŒDenseä¸­çš„å‚æ•°éƒ½å¯ä»¥è‡ªå·±è®¾å®šï¼Œä»¥åŠDenseçš„å±‚æ•°éƒ½å¯ä»¥è‡ªè¡Œè®¾å®š
    mlp_out = Dropout(0.5)(Dense(256, activation='relu')(concat_sparse_kd_embed))
    mlp_out = Dropout(0.3)(Dense(256, activation='relu')(mlp_out))
    mlp_out = Dropout(0.1)(Dense(256, activation='relu')(mlp_out))

    dnn_out = Dense(1)(mlp_out)

    return dnn_out


"""æ„å»ºDeepFMæ¨¡å‹â€”â€”DeepFMæ¨¡å‹"""


def DeepFM(linear_feature_columns, dnn_feature_columns):
    """
        è°ƒç”¨å‡½æ•°ï¼šbuild_input_layers, build_embedding_layers, get_linear_logits, get_fm_logits, get_dnn_logits
    """

    """è¾“å…¥å±‚"""
    # æ„å»ºè¾“å…¥å±‚ï¼Œè¿™é‡Œä½¿ç”¨å­—å…¸ï¼ˆdenseå’Œsparseä¸¤ç±»å­—å…¸ï¼‰çš„å½¢å¼è¿”å›ï¼Œæ–¹ä¾¿åç»­æ„å»ºæ¨¡å‹
    dense_input_dict, sparse_input_dict = build_input_layers(linear_feature_columns + dnn_feature_columns)

    # æ„å»ºè¾“å…¥å±‚ï¼Œè¾“å…¥å±‚ä¸èƒ½æ˜¯å­—å…¸çš„å½¢å¼ï¼Œåº”è¯¥å°†å­—å…¸çš„å½¢å¼è½¬æ¢æˆåˆ—è¡¨çš„å½¢å¼
    input_layers = list(dense_input_dict.values()) + list(sparse_input_dict.values())

    """ç»´åº¦ä¸ºkçš„embeddingå±‚"""
    # æ„å»ºç»´åº¦ä¸ºkçš„embeddingå±‚ï¼Œè¿™é‡Œä½¿ç”¨å­—å…¸çš„å½¢å¼è¿”å›ï¼Œæ–¹ä¾¿åé¢æ­å»ºæ¨¡å‹
    embedding_layers = build_embedding_layers(dnn_feature_columns, sparse_input_dict, is_linear=False)

    """è¾“å‡ºå±‚â€”â€”linear_logits"""
    # å°†linearéƒ¨åˆ†çš„ç‰¹å¾ä¸­sparseç‰¹å¾ç­›é€‰å‡ºæ¥ï¼Œåé¢ç”¨æ¥åš1ç»´çš„embedding
    linear_sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), linear_feature_columns))

    # linear_logitsè®¡ç®—denseç‰¹å¾çš„logitså’Œsparseç‰¹å¾çš„logitsä¸¤éƒ¨åˆ†ï¼Œæœ€åè®¡ç®—FMçš„ä¸€é˜¶ç‰¹å¾çš„logitså€¼
    linear_logits = get_linear_logits(dense_input_dict, sparse_input_dict, linear_sparse_feature_columns)

    """è¾“å‡ºå±‚â€”â€”fm_logits"""
    # å°†dnnéƒ¨åˆ†çš„ç‰¹å¾ä¸­sparseç‰¹å¾ç­›é€‰å‡ºæ¥
    dnn_sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), dnn_feature_columns))

    # fm_logitsåªè€ƒè™‘sparseç‰¹å¾çš„äºŒé˜¶äº¤å‰ï¼Œå°†æ‰€æœ‰çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œæœ€åè®¡ç®—FMçš„äºŒé˜¶äº¤å‰ç‰¹å¾çš„logitså€¼
    fm_logits = get_fm_logits(sparse_input_dict, dnn_sparse_feature_columns, embedding_layers)

    """è¾“å‡ºå±‚â€”â€”dnn_logits"""
    # dnn_logitsåªè€ƒè™‘sparseç‰¹å¾çš„é«˜é˜¶äº¤å‰ï¼Œå°†æ‰€æœ‰çš„embeddingæ‹¼æ¥åˆ°ä¸€èµ·è¾“å…¥åˆ°dnnä¸­ï¼Œæœ€åè®¡ç®—DNNçš„é«˜é˜¶äº¤å‰ç‰¹å¾çš„logitså€¼
    dnn_logits = get_dnn_logits(sparse_input_dict, dnn_sparse_feature_columns, embedding_layers)

    """è¾“å‡ºå±‚â€”â€”logitsï¼ˆå°†linear_logits, fm_logits, dnn_logitsç›¸åŠ ä½œä¸ºæœ€ç»ˆçš„logitsï¼‰"""
    output_logits = Add()([linear_logits, fm_logits, dnn_logits])

    """è¾“å‡ºå±‚â€”â€”sigmoidï¼ˆè¿™é‡Œçš„æ¿€æ´»å‡½æ•°ä½¿ç”¨sigmoidï¼‰"""
    output_layers = Activation("sigmoid")(output_logits)

    """æ¨¡å‹"""
    model = Model(input_layers, output_layers)

    return model


if __name__ == "__main__":
    """è¯»å–æ•°æ®"""
    path = '../data/'
    data_df = pd.read_csv(path + 'DeepFM_data.txt')

    """åˆ’åˆ†denseå’Œsparseç‰¹å¾"""
    columns = data_df.columns.values
    dense_features = [feat for feat in columns if 'I' in feat]
    sparse_features = [feat for feat in columns if 'C' in feat]

    """æ•°æ®é¢„å¤„ç†"""
    train_data = data_process(data_df, dense_features, sparse_features)
    train_data['label'] = data_df['label']

    """åˆ’åˆ† linear å’Œ dnn ç‰¹å¾(æ ¹æ®å®é™…åœºæ™¯è¿›è¡Œé€‰æ‹©)ï¼Œå¹¶å°†åˆ†ç»„åçš„ç‰¹å¾æ ‡è®°ä¸º DenseFeat å’Œ SparseFeat"""
    # ä½¿ç”¨å…·åå…ƒç»„å®šä¹‰ç‰¹å¾æ ‡è®°
    SparseFeat = namedtuple('SparseFeat', ['name', 'vocabulary_size', 'embedding_dim'])
    DenseFeat = namedtuple('DenseFeat', ['name', 'dimension'])

    linear_feature_columns = [SparseFeat(feat, vocabulary_size=data_df[feat].nunique(), embedding_dim=4)
                              for i, feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)
                                                                            for feat in dense_features]
    dnn_feature_columns = [SparseFeat(feat, vocabulary_size=data_df[feat].nunique(), embedding_dim=4)
                           for i, feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)
                                                                         for feat in dense_features]

    """æ„å»ºDeepFMæ¨¡å‹"""
    history = DeepFM(linear_feature_columns, dnn_feature_columns)
    history.summary()
    history.compile(optimizer="adam",
                    loss="binary_crossentropy",
                    metrics=["binary_crossentropy", tf.keras.metrics.AUC(name='auc')])

    """æ¨¡å‹è®­ç»ƒ"""
    # å°†è¾“å…¥æ•°æ®è½¬åŒ–æˆå­—å…¸çš„å½¢å¼è¾“å…¥
    train_model_input = {name: data_df[name] for name in dense_features + sparse_features}

    history.fit(train_model_input, train_data['label'].values, batch_size=64, epochs=5, validation_split=0.2, )
